import json
import logging
from typing import Dict, Any
from .llm_service import LLMService

# Configure logging
logger = logging.getLogger(__name__)

class DraftGenerator:
    """
    Service for generating legal drafts based on structured case data.
    Ensures strict adherence to provided legal sections to prevent hallucinations.
    """

    def __init__(self):
        self.llm_service = LLMService()

    def generate_draft(self, case_data: Dict[str, Any]) -> Dict[str, str]:
        """
        Generates a legal complaint draft using the LLM.

        Args:
            case_data (Dict[str, Any]): Dictionary containing:
                - issue_type
                - relevant_sections
                - precedents
                - legal_strength
                - action_steps

        Returns:
            Dict[str, str]: JSON containing:
                - complaint_title
                - draft_text
                - recommended_authority
        """
        required_input_keys = ["issue_type", "relevant_sections", "precedents", "legal_strength", "action_steps"]
        if not all(k in case_data for k in required_input_keys):
            logger.error(f"Missing keys in case_data. Expected {required_input_keys}")
            return self._get_fallback_response("Invalid input data.")

        # Construct a strict prompt
        prompt = self._construct_prompt(case_data)
        
        system_role = (
            "You are a strict Legal Drafting Assistant. "
            "You must generate a legal complaint based ONLY on the provided facts and laws. "
            "Do NOT hallucinate or reference laws not explicitly listed in 'relevant_sections'. "
            "Do NOT inject raw Python lists or Markdown formatting. "
            "Output must be valid JSON."
        )

        try:
            response_json_str = self.llm_service.generate_json_response(
                prompt=prompt, 
                system_role=system_role
            )

            if response_json_str:
                try:
                    response_data = json.loads(response_json_str)
                    
                    # Validation: Check strictly for required keys
                    required_output_keys = ["complaint_title", "draft_text", "recommended_authority"]
                    if not all(k in response_data for k in required_output_keys):
                         logger.warning("LLM response missing required keys.")
                         return self._get_fallback_response("Incomplete generation.")

                    # Validation: Ensure all values are strings
                    if not all(isinstance(response_data[k], str) for k in required_output_keys):
                        logger.warning("LLM response contains non-string values.")
                        return self._get_fallback_response("Invalid data types in response.")

                    # Validation: strict length check on draft_text
                    if len(response_data["draft_text"]) > 5000:
                        logger.warning("Draft text exceeded 5000 characters.")
                        return self._get_fallback_response("Draft too long.")

                    return response_data

                except json.JSONDecodeError:
                    logger.error("Failed to decode JSON from LLM response.")
                    return self._get_fallback_response("Output format error.")

            logger.warning("LLM service returned None.")
            return self._get_fallback_response("AI service unavailable.")

        except Exception as e:
            logger.error(f"Error generating draft: {str(e)}")
            return self._get_fallback_response("Internal execution error.")

    def _construct_prompt(self, data: Dict[str, Any]) -> str:
        """Constructs a strict, hallucination-resistant prompt."""
        
        # Serialize fields to JSON strings to avoid raw Python list injection
        relevant_sections_str = json.dumps(data.get('relevant_sections', []), indent=2)
        precedents_str = json.dumps(data.get('precedents', []), indent=2)
        action_steps_str = json.dumps(data.get('action_steps', []), indent=2)

        return f"""
You are a legal drafting assistant working inside a precedent-aware legal intelligence system.

You are provided structured legal analysis generated by a deterministic engine.

STRICT RULES:
- Use ONLY the legal sections listed under 'relevant_sections'.
- Do NOT invent new laws, acts, or sections.
- Do NOT modify the legal_strength value.
- Do NOT fabricate facts.
- If precedents list is empty, still generate a draft using issue_type and relevant_sections only.
- Output MUST be valid JSON.
- Do NOT include explanations outside JSON.
- Do NOT include markdown formatting.
- Return ONLY a JSON object.

INPUT DATA:
ISSUE TYPE:
{data.get('issue_type')}

RELEVANT SECTIONS (ONLY THESE MAY BE REFERENCED):
{relevant_sections_str}

PRECEDENTS:
{precedents_str}

LEGAL STRENGTH:
{data.get('legal_strength')}

ACTION STEPS:
{action_steps_str}

TASKS:

1. Generate a professional complaint_title.

2. Generate draft_text structured as:

   - Introduction
   - Statement of Facts
   - Legal Grounds (must reference only provided sections)
   - Relief Sought
   - Closing and Signature Placeholder

3. Suggest recommended_authority based on issue_type and action_steps.

OUTPUT FORMAT (STRICT):
Return a JSON object. Ensure all newlines within strings are escaped as \\n.
{{
  "complaint_title": "string",
  "draft_text": "string",
  "recommended_authority": "string"
}}
"""

    def _get_fallback_response(self, reason: str) -> Dict[str, str]:
        """Returns a safe fallback response."""
        return {
            "complaint_title": "Draft Generation Unavailable",
            "draft_text": f"System could not generate the draft at this time. Reason: {reason}. Please review inputs and try again.",
            "recommended_authority": "Consult Legal Expert"
        }
